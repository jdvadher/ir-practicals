{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reported-money",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package mac_morpho to\n",
      "[nltk_data]     C:\\Users\\hiren\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package mac_morpho is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hiren\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from six import iteritems\n",
    "from six.moves import xrange\n",
    "import unicodedata\n",
    "import nltk\n",
    "import six\n",
    "from nltk.corpus import mac_morpho\n",
    "nltk.download('mac_morpho')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ethical-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25(object):\n",
    "    PARAM_K1 = 1.2\n",
    "    PARAM_B = 0.75\n",
    "    EPSILON = 0.25\n",
    "\n",
    "    def __init__(self, corpus):\n",
    "        self.corpus_size = len(corpus)\n",
    "        self.dl = [float(len(d)) for d in corpus]\n",
    "        self.avgdl = sum(self.dl) / self.corpus_size\n",
    "        self.corpus = corpus\n",
    "        self.f = []\n",
    "        self.df = {}\n",
    "        self.idf = {}\n",
    "        self.average_idf = 0\n",
    "        self._initialize()\n",
    "\n",
    "    def _initialize(self):\n",
    "        for document in self.corpus:\n",
    "            frequencies = {}\n",
    "            for word in document:\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 0\n",
    "                frequencies[word] += 1\n",
    "            self.f.append(frequencies)\n",
    "\n",
    "            for word, freq in iteritems(frequencies):\n",
    "                if word not in self.df:\n",
    "                    self.df[word] = 0\n",
    "                self.df[word] += 1\n",
    "\n",
    "        for word, freq in iteritems(self.df):\n",
    "            self.idf[word] = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
    "\n",
    "        self.average_idf = sum(map(lambda k: float(self.idf[k]), self.idf.keys())) / len(self.idf.keys())\n",
    "\n",
    "    def _get_score(self, document, index):\n",
    "        score = 0\n",
    "        for word in document:\n",
    "            if word not in self.f[index]:\n",
    "                continue\n",
    "            idf = self.idf[word] if self.idf[word] >= 0 else self.EPSILON * self.average_idf\n",
    "            score += (idf * self.f[index][word] * (self.PARAM_K1 + 1)\n",
    "                      / (self.f[index][word] + self.PARAM_K1 * (1 - self.PARAM_B + self.PARAM_B * self.dl[index] / self.avgdl)))\n",
    "        return score\n",
    "\n",
    "    def _get_scores(self, document):\n",
    "        scores = []\n",
    "        for index in xrange(self.corpus_size):\n",
    "            score = self._get_score(document, index)\n",
    "            scores.append(score)\n",
    "        return scores\n",
    "\n",
    "    def ranked(self, query, length):\n",
    "        \"\"\"Returns the `length` most relevant documents according to `query`\"\"\"\n",
    "        scores = [(index, score) for index, score in enumerate(self._get_scores(query))]\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        indexes, _ = self._unpack(scores)\n",
    "        return indexes[:length]\n",
    "\n",
    "    @staticmethod\n",
    "    def _unpack(tuples):\n",
    "        return zip(*tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "constitutional-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_terms(terms):\n",
    "    \"\"\"Remove diacritics from terms and turn case to lowercase\"\"\"\n",
    "    # Aqui vocÃª pode adicionar outros tratamentos:\n",
    "    # - remover stopwords\n",
    "    # - remover numerais\n",
    "    # - stemming\n",
    "    return [remove_diacritics(term).lower() for term in terms]\n",
    "\n",
    "\n",
    "def remove_diacritics(text, encoding='utf8'):\n",
    "    \"\"\"Remove diacritics from bytestring or unicode, returning an unicode string\"\"\"\n",
    "    nfkd_form = unicodedata.normalize('NFKD', to_unicode(text, encoding))\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return only_ascii.decode(encoding)\n",
    "\n",
    "\n",
    "def to_unicode(text, encoding='utf8'):\n",
    "    \"\"\"Convert a string (bytestring in `encoding` or unicode), to unicode.\"\"\"\n",
    "    if isinstance(text, six.text_type):\n",
    "        return text\n",
    "    return text.decode(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "following-executive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jersei', 'atinge', 'media', 'de', 'cr$', '1,4', 'milhao', 'em', 'a', 'venda', 'de', 'a', 'pinhal', 'em', 'sao', 'paulo']\n",
      "0 - \" ainda ha inflacao e o aumento de prazo vem acompanhado de alguma correcao \" , diz sastre\n",
      "1 - a queda de a inflacao , segundo o empresario , da a o primeiro a chance de negociar o animal por o seu real valor\n",
      "2 - jersei atinge media de cr$ 1,4 milhao em a venda de a pinhal em sao paulo\n",
      "3 - programe sua viagem a a exposicao nacional do zebu , que comeca dia 25\n",
      "4 - safra recorde e disponibilidade de credito ativam vendas de maquinas agricolas\n"
     ]
    }
   ],
   "source": [
    "news = [normalize_terms(sentence) for sentence in mac_morpho.sents()]\n",
    "print(repr(news[0]))\n",
    "\n",
    "bm25 = BM25(news[:1000])\n",
    "query = normalize_terms(nltk.word_tokenize('inflacao'))\n",
    "for position, index in enumerate(bm25.ranked(query, 5)):\n",
    "    print('{} - {}'.format(position, ' '.join(news[index])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iim",
   "language": "python",
   "name": "iim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
